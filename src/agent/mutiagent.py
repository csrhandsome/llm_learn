import os
import json
import asyncio
import time
import datetime
import operator
from typing import Any, Annotated, Dict, List, Optional, Set, TYPE_CHECKING, TypedDict
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import BaseMessage
from langchain.agents.middleware import (
    ContextEditingMiddleware,
    ClearToolUsesEdit,
    ToolRetryMiddleware,
    SummarizationMiddleware,
)
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage
from pathlib import Path
import tqdm

from src.agent.prompt import (
    SYSTEM_PROMPT,
    USER_INPUT_TEMPLATE,
    ERROR_FEEDBACK_TEMPLATE,
    EMPTY_RESULT_FEEDBACK_TEMPLATE,
    RESULT_VERIFICATION_TEMPLATE,
)
from src.util import load_questions, safe_read_json_with_lock, safe_write_json_with_lock
from src.database.sql_exe import execute_sql_with_pymysql
from src.config import LLM_CONFIG
from src.config import DB_CONFIG
from src.tool import (
    # é˜¶æ®µæ€§å·¥å…·é›†
    SCHEMA_PLANNING_TOOLS,
    EXEMPLAR_TOOLS,
    SQL_GENERATION_TOOLS,
    VALIDATION_EXECUTION_TOOLS,
    # å®Œæ•´å·¥å…·é›†
    ALL_TOOLS,
    CORE_TOOLS,
    ADVANCED_TOOLS,
)
from agent.base_agent import BaseAgent


class AgentState(TypedDict):
    """State shared across LangGraph nodes."""

    messages: Annotated[List[BaseMessage], operator.add]


class MutiAgent(BaseAgent):
    def __init__(
        self,
        model_name: Optional[
            str
        ] = None,  # é»˜è®¤æ¨¡å‹ï¼Œå¯é€‰: "deepseek-ai/DeepSeek-V3.2-Exp", "MiniMaxAI/MiniMax-M2", "zai-org/GLM-4.6"
    ):
        self.model_name = model_name or LLM_CONFIG["model_name"]
        self.llm = self._generate_llm(self.model_name)
        # agneté‡Œé¢å†…ç½®äº†AgentStateï¼Œåœ¨æ¯æ¬¡invokeçš„æ—¶å€™å¯ä»¥ä¿å­˜è®°å¿†
        self.agent = self._generate_agent()
        self.sql_executor = execute_sql_with_pymysql()
        self.all_questions = load_questions(Path("data/final_dataset.json"))

    def _generate_tools(self) -> List[Any]:
        """ç”Ÿæˆé»˜è®¤å·¥å…·åˆ—è¡¨

        MutiAgent ä½¿ç”¨åˆ†é˜¶æ®µçš„å·¥å…·é›†ï¼Œæ­¤æ–¹æ³•è¿”å›æ‰€æœ‰å¯ç”¨å·¥å…·ã€‚
        å®é™…ä½¿ç”¨æ—¶é€šè¿‡ _build_stage_agent ä¸ºæ¯ä¸ªé˜¶æ®µæŒ‡å®šä¸åŒçš„å·¥å…·ã€‚

        Returns:
            æ‰€æœ‰å¯ç”¨å·¥å…·çš„åˆ—è¡¨
        """
        return ALL_TOOLS

    def _generate_llm(self, model_name: str = None) -> ChatOpenAI:
        """ç”Ÿæˆ LLM å®ä¾‹ï¼Œæ”¯æŒå¤šç§æ¨¡å‹

        æ”¯æŒçš„æ¨¡å‹:
        1. deepseek-ai/DeepSeek-V3.2-Exp: DeepSeek å®éªŒæ€§æ¨¡å‹ï¼Œä½¿ç”¨ DSA ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶
        2. MiniMaxAI/MiniMax-M2: ç´§å‡‘é«˜æ•ˆçš„ MoE æ¨¡å‹ï¼Œ230B æ€»å‚æ•°ï¼Œ10B æ¿€æ´»å‚æ•°
        3. zai-org/GLM-4.6: GLM-4.6ï¼Œ200K ä¸Šä¸‹æ–‡çª—å£ï¼Œå¼ºå¤§çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›

        Args:
            model_name: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹

        Returns:
            ChatOpenAI å®ä¾‹
        """
        if model_name is None:
            model_name = LLM_CONFIG["model_name"]

        return ChatOpenAI(
            model=model_name,
            api_key=LLM_CONFIG["api_key"],
            base_url=LLM_CONFIG["base_url"],
            temperature=0.0,
        )

    def _build_stage_agent(self, *, llm: ChatOpenAI, tools: List[Any]):
        """Helper to build a stage-specific LangGraph agent."""

        return create_agent(
            llm,
            system_prompt=SYSTEM_PROMPT,
            tools=tools,
            middleware=self._generate_middleware(llm=llm),
        )

    def _generate_agent(self):
        """æ„å»ºä¸€ä¸ªç”±å¤šä¸ªå·¥å…·èŠ‚ç‚¹ç»„æˆçš„ LangGraph workflowã€‚

        æ¯ä¸ªé˜¶æ®µä½¿ç”¨ä¸åŒçš„æ¨¡å‹ä»¥ä¼˜åŒ–æ€§èƒ½å’Œæˆæœ¬:
        1. Schema åˆ†æé˜¶æ®µ: ä½¿ç”¨ GLM-4.6 (200K ä¸Šä¸‹æ–‡ï¼Œé€‚åˆç†è§£å¤æ‚ schema)
        2. ç¤ºä¾‹æ£€ç´¢é˜¶æ®µ: ä½¿ç”¨ MiniMax-M2 (å¿«é€Ÿé«˜æ•ˆï¼Œé€‚åˆæ£€ç´¢ä»»åŠ¡)
        3. SQL ç”Ÿæˆé˜¶æ®µ: ä½¿ç”¨ DeepSeek-V3.2-Exp (å¼ºå¤§çš„ä»£ç ç”Ÿæˆèƒ½åŠ›)
        4. éªŒè¯æ‰§è¡Œé˜¶æ®µ: ä½¿ç”¨ GLM-4.6 (å¼ºå·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œé€‚åˆè°ƒè¯•)
        """
        # è¿™ä¸€å—ä¿®æ”¹ä¸€ä¸‹ï¼Œç°åœ¨æ˜¯æ¨¡ä»¿agent.pyé‡Œé¢çš„æ“ä½œï¼Œç¬¬ä¸€ä¸ªç”¨"zai-org/GLM-4.6"æ¥å®Œæˆç°åœ¨çš„å‰ä¸‰ä¸ªé˜¶æ®µçš„å·¥ä½œã€‚ç„¶åç”¨"zai-org/GLM-4.6"å’ŒMiniMax-M2æ¥è¯„å®¡è¿™ä¸ªä»»åŠ¡ï¼Œç„¶åç»¼åˆä¸€ä¸ªè¾“å‡ºã€‚å¸¸ä½ä¸€ä¸ªdeepseekçš„agent,å¦‚æœæœ‰é”™è¯¯å°±è®¤çœŸåˆ†æé”™è¯¯ï¼Œå¦‚æœæ²¡æœ‰é”™è¯¯å°±è·³è¿‡

        # é˜¶æ®µ 1: Schema åˆ†æ - ä½¿ç”¨ GLM-4.6 (200K ä¸Šä¸‹æ–‡çª—å£ï¼Œé€‚åˆç†è§£å¤æ‚ schema)
        schema_llm = self._generate_llm("zai-org/GLM-4.6")
        schema_agent = self._build_stage_agent(
            llm=schema_llm, tools=SCHEMA_PLANNING_TOOLS
        )

        # é˜¶æ®µ 2: ç¤ºä¾‹æ£€ç´¢ - ä½¿ç”¨ MiniMax-M2 (ç´§å‡‘é«˜æ•ˆï¼Œ10B æ¿€æ´»å‚æ•°)
        exemplar_llm = self._generate_llm("MiniMaxAI/MiniMax-M2")
        exemplar_agent = self._build_stage_agent(llm=exemplar_llm, tools=EXEMPLAR_TOOLS)

        # é˜¶æ®µ 3: SQL ç”Ÿæˆ - ä½¿ç”¨ DeepSeek-V3.2-Exp (å¼ºå¤§çš„ä»£ç ç”Ÿæˆå’Œæ¨ç†èƒ½åŠ›)
        generation_llm = self._generate_llm("deepseek-ai/DeepSeek-V3.2-Exp")
        generation_agent = self._build_stage_agent(
            llm=generation_llm, tools=SQL_GENERATION_TOOLS
        )

        # é˜¶æ®µ 4: éªŒè¯æ‰§è¡Œ - ä½¿ç”¨ GLM-4.6 (å¼ºå·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œé€‚åˆè°ƒè¯•å’ŒéªŒè¯)
        validation_llm = self._generate_llm("zai-org/GLM-4.6")
        validation_agent = self._build_stage_agent(
            llm=validation_llm,
            tools=VALIDATION_EXECUTION_TOOLS,
        )

        # æ„å»º StateGraph workflow
        # create_agent è¿”å›çš„ agent æœ¬èº«å°±æ˜¯ä¸€ä¸ªå¯è°ƒç”¨çš„èŠ‚ç‚¹ï¼Œä¸éœ€è¦é¢å¤–åŒ…è£…
        builder = StateGraph(AgentState)
        builder.add_node("schema_analysis", schema_agent)
        builder.add_node("example_retrieval", exemplar_agent)
        builder.add_node("sql_generation", generation_agent)
        builder.add_node("sql_validation", validation_agent)

        # å®šä¹‰èŠ‚ç‚¹é—´çš„æµè½¬é¡ºåº
        builder.add_edge(START, "schema_analysis")
        builder.add_edge("schema_analysis", "example_retrieval")
        builder.add_edge("example_retrieval", "sql_generation")
        builder.add_edge("sql_generation", "sql_validation")
        builder.add_edge("sql_validation", END)

        return builder.compile(checkpointer=InMemorySaver())

    async def _call_llm(
        self, messages: List[Any], thread_id: str = "default"
    ) -> dict[str, Any] | Any:
        """è°ƒç”¨agent,agentæ ¹æ®toolsåˆ—è¡¨æ¥åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å·¥å…·å¹¶æ‰§è¡Œ,è¿”å›å“åº”ã€‚

        Args:
            messages: å½“å‰è½®æ¬¡çš„æ–°æ¶ˆæ¯åˆ—è¡¨,LangChainä¼šè‡ªåŠ¨é€šè¿‡thread_idåŠ è½½å†å²æ¶ˆæ¯
            thread_id: å¯¹è¯çº¿ç¨‹ID,ç”¨äºéš”ç¦»ä¸åŒé—®é¢˜çš„å¯¹è¯å†å²ã€‚æ¯ä¸ªé—®é¢˜åº”ä½¿ç”¨å”¯ä¸€çš„thread_id

        """

        # LangChainé€šè¿‡checkpointerå’Œthread_idè‡ªåŠ¨ç®¡ç†å¯¹è¯å†å²
        # æ¯ä¸ªé—®é¢˜ä½¿ç”¨ç‹¬ç«‹çš„thread_idï¼Œé¿å…å†å²åœ¨ä¸åŒé—®é¢˜é—´ç´¯ç§¯
        result = await self.agent.ainvoke(
            {
                "messages": messages,
            },
            config={
                "configurable": {
                    "thread_id": thread_id,
                    "max_iterations": 150,  # æœ€å¤š15æ¬¡è¿­ä»£ï¼ˆå·¥å…·è°ƒç”¨ï¼‰é˜²æ­¢æ— é™å¾ªç¯
                },
                "recursion_limit": 100,  # é™ä½é€’å½’é™åˆ¶åˆ°50ï¼Œæ›´æ—©å‘ç°æ­»å¾ªç¯é—®é¢˜
            },  # ä½¿ç”¨ä¼ å…¥çš„thread_idï¼Œä¸ºæ¯ä¸ªé—®é¢˜åˆ›å»ºç‹¬ç«‹çš„å¯¹è¯å†å²
            # context=context,  # ä¼ é€’contextç»™agent
        )

        return result

    def _generate_middleware(self, llm: Optional[ChatOpenAI] = None):
        """langchainçš„ä¸­é—´ä»¶

        ä¸­é—´ä»¶åˆ—è¡¨:
        1. SummarizationMiddleware: å½“å¯¹è¯å†å²è¿‡é•¿æ—¶è‡ªåŠ¨æ€»ç»“ï¼Œé¿å… token è¶…é™
        2. ToolRetryMiddleware: å·¥å…·è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•
        """
        llm = llm or self.llm
        return [
            # æ‘˜è¦ä¸­é—´ä»¶ - é˜²æ­¢å¯¹è¯å†å²è¿‡é•¿å¯¼è‡´ token è¶…é™
            SummarizationMiddleware(
                model=llm,  # ä½¿ç”¨ç»æµå‹æ¨¡å‹è¿›è¡Œæ‘˜è¦
                max_tokens_before_summary=140000,  # å¯¹è¯è¾¾åˆ° 100k tokens æ—¶è§¦å‘æ‘˜è¦
                messages_to_keep=15,  # æ‘˜è¦åä¿ç•™æœ€è¿‘ 15 æ¡æ¶ˆæ¯
                summary_prompt="""è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯å†å²ï¼Œä¿ç•™å…³é”®ä¿¡æ¯:
1. ç”¨æˆ·çš„åŸå§‹é—®é¢˜å’Œéœ€æ±‚
2. å·²è¯†åˆ«çš„æ•°æ®åº“è¡¨å’Œåˆ—
3. SQL ç”Ÿæˆè¿‡ç¨‹ä¸­çš„é‡è¦å†³ç­–
4. é‡åˆ°çš„é”™è¯¯å’Œä¿®å¤æ–¹æ³•
5. å½“å‰çš„ SQL æŸ¥è¯¢çŠ¶æ€
6. è°ƒç”¨äº†å“ªäº›å·¥å…·ä»¥åŠå®ƒä»¬çš„è¾“å‡º
æ€»ç»“åº”è¯¥ç®€æ´ä½†åŒ…å«æ‰€æœ‰å¿…è¦çš„ä¸Šä¸‹æ–‡ï¼Œä»¥ä¾¿ç»§ç»­å¯¹è¯ã€‚""",
            ),
            # å·¥å…·é‡è¯•ä¸­é—´ä»¶ - å·¥å…·è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•
            ToolRetryMiddleware(
                max_retries=3,  # æœ€å¤šé‡è¯• 3 æ¬¡
                backoff_factor=2.0,  # æŒ‡æ•°é€€é¿å€æ•°
                initial_delay=1.0,  # åˆå§‹å»¶è¿Ÿ 1 ç§’
                max_delay=60.0,  # æœ€å¤§å»¶è¿Ÿ 60 ç§’
                jitter=True,  # æ·»åŠ éšæœºæŠ–åŠ¨é¿å…é›·é¸£ç¾Šç¾¤æ•ˆåº”
            ),
        ]

    def _append_assistant_tool_message(
        self, messages: List[Any], assistant_message
    ) -> None:
        """å°†åŒ…å«tool_callsçš„assistantæ¶ˆæ¯è¿½åŠ åˆ°å¯¹è¯å†å²ã€‚"""
        if assistant_message is None:
            return

        message_obj = assistant_message

        if isinstance(message_obj, tuple):
            for item in message_obj:
                if hasattr(item, "content") or isinstance(item, dict):
                    message_obj = item
                    break
        elif isinstance(message_obj, list):
            for item in message_obj:
                if hasattr(item, "content") or isinstance(item, dict):
                    message_obj = item
                    break

        if isinstance(message_obj, dict):
            content = message_obj.get("content", "") or ""
            tool_calls = message_obj.get("tool_calls") or []
        else:
            content = getattr(message_obj, "content", "") or ""
            tool_calls = getattr(message_obj, "tool_calls", None)

        if tool_calls:
            formatted_calls: List[Dict[str, Any]] = []
            for tool_call in tool_calls:
                tool_name = tool_call.get("name")
                tool_id = tool_call.get("id")
                tool_type = tool_call.get("type")
                tool_args = tool_call.get("args", {}) or {}
                formatted_calls.append(
                    {
                        "id": tool_id,
                        "type": tool_type,
                        "function": {
                            "name": tool_name,
                            "arguments": json.dumps(tool_args, ensure_ascii=False),
                        },
                    }
                )
            # ä½¿ç”¨ AIMessage å¹¶ä¼ é€’ tool_calls
            ai_message = AIMessage(
                content=content, additional_kwargs={"tool_calls": formatted_calls}
            )
            messages.append(ai_message)
        else:
            messages.append(AIMessage(content=content))

    def _extract_messages(self, **kwargs) -> List[Any]:
        """ä» kwargs ä¸­æå–æ¶ˆæ¯åˆ—è¡¨ï¼Œé»˜è®¤è¿”å›ç©ºåˆ—è¡¨ã€‚"""
        messages = kwargs.get("messages")
        return messages if isinstance(messages, list) else []

    def _generate_user_text(
        self, query: str, table_list: List[str], knowledge: str
    ) -> str:
        """ç”Ÿæˆç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œä½¿ç”¨æ¨¡æ¿æ ¼å¼åŒ–"""
        # æ ¼å¼åŒ– table_list
        formatted_tables = ", ".join(table_list)
        # æ ¼å¼åŒ– knowledge
        formatted_knowledge = knowledge if knowledge else "None"

        # ä½¿ç”¨æ¨¡æ¿
        user_text = USER_INPUT_TEMPLATE.format(
            query=query, table_list=formatted_tables, knowledge=formatted_knowledge
        )
        return user_text

    def _extract_sql_from_response(self, response: str) -> str:
        """ä» LLM å“åº”ä¸­æå– SQL è¯­å¥

        Args:
            response: LLM çš„å®Œæ•´å“åº”

        Returns:
            æå–çš„ SQL å­—ç¬¦ä¸²
        """
        # å°è¯•ä» ```sql ... ``` ä¸­æå–
        if "```sql" in response:
            sql = response.split("```sql")[-1].split("```")[0].strip()
            return sql
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æ‰¾ SELECT å¼€å¤´çš„è¯­å¥
        elif "SELECT" in response.upper():
            lines = response.split("\n")
            sql_lines = []
            in_sql = False
            for line in lines:
                if "SELECT" in line.upper():
                    in_sql = True
                if in_sql:
                    sql_lines.append(line)
                    # å¦‚æœé‡åˆ°åˆ†å·ï¼Œç»“æŸ
                    if ";" in line:
                        break
            return "\n".join(sql_lines).strip()
        else:
            print(f"Error extracting SQL")
            return response.strip()

    async def solve_question(
        self, question_data: Dict[str, str], messages: List[Any], attempt: int = 0
    ) -> Dict[str, str]:
        """è§£å†³ä¸€ä¸ªé—®é¢˜ï¼Œç”Ÿæˆå¹¶æ‰§è¡Œ SQL

        æ­¤æ–¹æ³•ä¼šï¼š
        1. è°ƒç”¨ Agent ç”Ÿæˆ SQL
        2. æ‰§è¡Œ SQL å¹¶è¿”å›ç»“æœ
        3. å¦‚æœå¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯ï¼ˆç”± main å‡½æ•°å†³å®šæ˜¯å¦é‡è¯•ï¼‰

        Args:
            question_data: åŒ…å« question, table_list, knowledge, sql_id çš„å­—å…¸
            messages: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨
            attempt: å½“å‰å°è¯•æ¬¡æ•°ï¼ˆç”¨äºç”Ÿæˆ thread_idï¼‰

        Returns:
            Dict: åŒ…å« sql_id, sql, status, result/error_message çš„å­—å…¸
        """
        sql_id = question_data.get("sql_id", "")
        # è°ƒç”¨ LLM ç”Ÿæˆ SQL
        # ä½¿ç”¨ sql_id_attempt ä½œä¸º thread_idï¼Œæ¯æ¬¡å°è¯•ä½¿ç”¨ä¸åŒçš„ thread_id
        # attempt_id = f"{sql_id}_{attempt}"
        attempt_id = sql_id
        result = await self._call_llm(messages, thread_id=attempt_id)

        # ä»ç»“æœä¸­æå– SQL
        if "messages" in result:
            last_message = result["messages"][-1]
            if isinstance(last_message, AIMessage):
                response_text = last_message.content
            else:
                response_text = str(last_message)
        else:
            response_text = str(result)

        # è§£æ SQL
        sql = self._extract_sql_from_response(response_text)

        # æ‰§è¡Œ SQL éªŒè¯
        exec_result = self.sql_executor.execute_single_sql(sql, DB_CONFIG)

        # è¿”å›ç»“æœï¼ˆåŒ…å«æ‰§è¡ŒçŠ¶æ€ï¼‰
        return {
            "sql_id": sql_id,
            "sql": sql,
            "status": exec_result["status"],
            "result": exec_result.get("result"),
            "error_message": exec_result.get("error_message"),
        }


async def main():
    """ä¸»å‡½æ•°ï¼šæ‰¹é‡å¤„ç†é—®é¢˜ï¼Œç”Ÿæˆå¹¶éªŒè¯ SQL"""
    # å®šä¹‰è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_filepath = Path("data/final_dataset.json")
    generated_sqls_path = Path("generated_sqls.json")  # ä¸´æ—¶æ–‡ä»¶
    final_output_filepath = Path("dataset_exe_result_mutiagent.json")  # æœ€ç»ˆæäº¤æ–‡ä»¶
    max_retries = 12  # æœ€å¤§é‡è¯•æ¬¡æ•°

    all_questions = load_questions(input_filepath)
    agent = MutiAgent()

    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼ŒåŠ è½½å·²å®Œæˆçš„ç»“æœï¼ˆä½¿ç”¨æ–‡ä»¶é”ï¼‰
    completed_ids = set()
    results_list = safe_read_json_with_lock(final_output_filepath)
    if results_list:
        completed_ids = {item["sql_id"] for item in results_list}
        print(f"ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼Œå·²å®Œæˆ {len(completed_ids)} ä¸ªä»»åŠ¡")
    else:
        print("æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œä»å¤´å¼€å§‹")

    count = 0
    # ç”Ÿæˆç­”æ¡ˆï¼ˆå¸¦è‡ªåŠ¨é‡è¯•å’ŒéªŒè¯ï¼‰
    for question_data in tqdm.tqdm(all_questions, desc="Agent æ­£åœ¨ç”Ÿæˆ SQL"):
        query = question_data.get("question", "")
        table_list = question_data.get("table_list", [])
        knowledge = question_data.get("knowledge", "")
        sql_id = question_data.get("sql_id", "")
        golden_sql = question_data.get("golden_sql", "")

        count += 1
        last_check = False
        # if count < 95:
        #     continue

        # è·³è¿‡å·²å®Œæˆçš„ä»»åŠ¡
        if sql_id in completed_ids:
            print(f"â­ {sql_id} å·²å®Œæˆï¼Œè·³è¿‡")
            continue
        # å¦‚æœæ˜¯golden_sqlï¼Œç›´æ¥æ‰§è¡Œå·²æœ‰SQL
        if golden_sql:
            exec_result = agent.sql_executor.execute_single_sql(
                question_data.get("sql", ""), DB_CONFIG
            )
            final_result = {
                "sql_id": sql_id,
                "sql": question_data.get("sql", ""),
                "status": exec_result["status"],
                "result": exec_result.get("result"),
            }
            print(f"âœ“ {sql_id} ä½¿ç”¨ Golden SQL (è·³è¿‡ Agent)")

            # ä½¿ç”¨æ–‡ä»¶é”å®‰å…¨å†™å…¥
            results_list = safe_write_json_with_lock(
                final_output_filepath, final_result
            )
            completed_ids.add(sql_id)
            continue
        # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆç”¨æˆ·è¾“å…¥
        user_text = agent._generate_user_text(query, table_list, knowledge)

        # åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨
        messages = [HumanMessage(content=user_text)]

        # é‡è¯•å¾ªç¯
        final_result = None
        for attempt in range(max_retries):
            # è°ƒç”¨ solve_question ç”Ÿæˆå¹¶æ‰§è¡Œ SQL
            result = await agent.solve_question(question_data, messages, attempt)

            # å¦‚æœæ‰§è¡ŒæˆåŠŸï¼Œæ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
            if result["status"] == "success":
                result_data = result.get("result", [])

                # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
                if not result_data or len(result_data) == 0:
                    # ç»“æœä¸ºç©ºï¼Œè¦æ±‚ Agent æ£€æŸ¥è´¨é‡
                    if attempt < max_retries - 1:
                        print(
                            f"{sql_id} SQL æ‰§è¡ŒæˆåŠŸä½†ç»“æœä¸ºç©º (å°è¯• {attempt + 1}/{max_retries})"
                        )

                        # ä½¿ç”¨æ¨¡æ¿æ„å»ºåé¦ˆæ¶ˆæ¯
                        empty_result_feedback = EMPTY_RESULT_FEEDBACK_TEMPLATE.format(
                            sql=result["sql"]
                        )
                        messages.append(HumanMessage(content=empty_result_feedback))
                        continue
                    else:
                        # ä¸ä¸ºç©ºï¼Œæ˜¯æˆåŠŸçš„

                        # å¦‚æœè¿˜æ²¡æœ‰è¿›è¡Œæœ€ç»ˆæ£€æŸ¥ï¼Œä¸”è¿˜æœ‰é‡è¯•æœºä¼šï¼Œè®© LLM éªŒè¯ç»“æœ
                        if not last_check and attempt < max_retries - 4:
                            last_check = True
                            print(f"ğŸ” {sql_id} å°†æ‰§è¡Œç»“æœä¼ å…¥ LLM è¿›è¡Œæœ€ç»ˆéªŒè¯")

                            # æ„å»ºç»“æœéªŒè¯æ¶ˆæ¯
                            result_preview = (
                                result_data[:5] if len(result_data) > 5 else result_data
                            )
                            verification_message = RESULT_VERIFICATION_TEMPLATE.format(
                                sql=result["sql"],
                                result_preview=result_preview,
                                result_count=len(result_data),
                                original_question=query,
                            )
                            messages.append(HumanMessage(content=verification_message))
                            continue  # ç»§ç»­å¾ªç¯ï¼Œè®© LLM æœ‰æœºä¼šä¼˜åŒ–

                        # æœ€ç»ˆæ£€æŸ¥åï¼Œæˆ–æ²¡æœ‰æœ€ç»ˆæ£€æŸ¥æœºä¼šï¼Œä¿å­˜ç»“æœ
                        final_result = {
                            "sql_id": sql_id,
                            "sql": result["sql"],
                            "status": "success",
                            "result": result_data,
                        }
                        break

            # å¦‚æœæ‰§è¡Œå¤±è´¥ä¸”è¿˜æœ‰é‡è¯•æœºä¼šï¼Œå°†é”™è¯¯ä¿¡æ¯åé¦ˆç»™ Agent
            if attempt < max_retries - 1:
                error_msg = result["error_message"]
                print(
                    f"âœ— {sql_id} SQL æ‰§è¡Œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {error_msg[:100]}..."
                )

                # ä½¿ç”¨æ¨¡æ¿æ„å»ºé”™è¯¯åé¦ˆæ¶ˆæ¯
                feedback_text = ERROR_FEEDBACK_TEMPLATE.format(
                    sql=result["sql"], error_message=error_msg
                )
                messages.append(HumanMessage(content=feedback_text))
            else:
                # å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¿å­˜æœ€åçš„é”™è¯¯
                print(f"âœ— {sql_id} SQL æ‰§è¡Œå¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                final_result = {
                    "sql_id": sql_id,
                    "sql": result["sql"],
                    "status": "error",
                    "error_message": result["error_message"],
                }

        # æ·»åŠ æœ€ç»ˆç»“æœåˆ°åˆ—è¡¨
        if final_result:
            # ä½¿ç”¨æ–‡ä»¶é”å®‰å…¨å†™å…¥ï¼ˆå®æ—¶è¿½åŠ ï¼‰
            results_list = safe_write_json_with_lock(
                final_output_filepath, final_result
            )
            completed_ids.add(sql_id)

    # æœ€ç»ˆç»“æœå·²ç»é€šè¿‡æ–‡ä»¶é”å®æ—¶ä¿å­˜ï¼Œè¿™é‡Œä¸éœ€è¦å†æ¬¡ä¿å­˜
    print(f"\nâœ… æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {final_output_filepath}")

    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results_list if r["status"] == "success")
    error_count = len(results_list) - success_count
    print(f"æˆåŠŸ: {success_count}, å¤±è´¥: {error_count}")


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())
