{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1b52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebab10",
   "metadata": {},
   "source": [
    "以上为导入环境的步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfb6a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我是Kimi，一个由月之暗面科技有限公司（Moonshot AI）训练的大语言模型。我的知识截止时间是2025年4月，擅长用自然流畅的语言和你互动交流。有什么可以帮你的吗？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 10, 'total_tokens': 56, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'kimi-k2-turbo-preview', 'system_fingerprint': None, 'id': 'chatcmpl-6926935f271effa59ed7af65', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--848473e9-00cb-493f-8e11-0f94a435e1b5-0' usage_metadata={'input_tokens': 10, 'output_tokens': 46, 'total_tokens': 56, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "# --- LLM API 配置 ---\n",
    "LLM_CONFIG = {\n",
    "    # 替换为你的 API Key\n",
    "    \"api_key\": \"sk-stgjqeuzoevxkohlssoiqcpjdydttorxsccrhnfhlmrflawh\",\n",
    "    # 替换为你的 API 接入点 (Base URL)\n",
    "    # 例如 DeepSeek: 'https://api.deepseek.com'\n",
    "    \"base_url\": \"https://api.siliconflow.cn/v1/\",\n",
    "    # 替换为你需要使用的模型名称\n",
    "    \"model_name\": \"zai-org/GLM-4.6\",\n",
    "}\n",
    "LLM_CONFIG = {\n",
    "    # 替换为你的 API Key\n",
    "    \"api_key\": \"sk-PJfHRIM2Q0K8vXajt7pBjrXFhxbVP3GSsqw6KItdSM2MvOf4\",\n",
    "    # 替换为你的 API 接入点 (Base URL)\n",
    "    # 例如 DeepSeek: 'https://api.deepseek.com'\n",
    "    \"base_url\": \"https://api.moonshot.cn/v1\",\n",
    "    # 替换为你需要使用的模型名称\n",
    "    \"model_name\": \"kimi-k2-turbo-preview\",\n",
    "}\n",
    "\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "            model=LLM_CONFIG[\"model_name\"],\n",
    "            api_key=LLM_CONFIG[\"api_key\"],\n",
    "            base_url=LLM_CONFIG[\"base_url\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "response=llm.invoke(\"你是什么模型\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f995b2f",
   "metadata": {},
   "source": [
    "这个为新建的llm的接口，通过这个接口我们能够调用我们的模型来完成各种各样的任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f395acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是**第一次**调用。  \n",
      "如果你之前没有在这个对话中发过类似“这是第几次调用？”的问题，那这就是第一次。  \n",
      "如果你已经问过很多次了，那这次就是**第 N 次**，但我这边不会记录你之前在其他对话里的提问次数。  \n",
      "\n",
      "所以，**在这次对话里，这是第一次。**\n",
      "这是**第一次**调用。  \n",
      "如果你之前已经和我对话过，那可能是**新的会话**，但在当前这个对话里，这是你第一次发消息。  \n",
      "你可以告诉我“这是第几次”，我会根据你设定的上下文来配合你。\n",
      "我这边看不到实时时间，但你可以看一下你设备上的时间，那就是现在的准确时间。如果你需要我帮你算时差或者设置提醒，随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(\n",
    "            model=LLM_CONFIG[\"model_name\"],\n",
    "            api_key=LLM_CONFIG[\"api_key\"],\n",
    "            base_url=LLM_CONFIG[\"base_url\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "response=llm.invoke(\"这是第几次调用？\")\n",
    "print(response.content)\n",
    "response=llm.invoke(\"这是第几次调用？\")\n",
    "print(response.content)\n",
    "response=llm.invoke(\"这是几点了？\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59088755",
   "metadata": {},
   "source": [
    "现在我们尝试来建立一个agent,langchain的agent拥有可以不断思考然后再执行的能力,可以给agent配置各种各样的工具和记忆功能，来让agent完成复杂的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11fb7c",
   "metadata": {},
   "source": [
    "我们首先来给agent配置一个记忆的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32181e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是第 **1** 次调用。\n",
      "这是第 **2** 次调用。\n",
      "现在是 **14:27**（北京时间）。\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(\n",
    "            model=LLM_CONFIG[\"model_name\"],\n",
    "            api_key=LLM_CONFIG[\"api_key\"],\n",
    "            base_url=LLM_CONFIG[\"base_url\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "SYSTEM_PROMPT=\"你是一个智能的助理,你能够根据用户的问题来调用llm。快速的回答用户。\"\n",
    "agent = create_agent(\n",
    "            llm,\n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            checkpointer=InMemorySaver(),\n",
    "        )\n",
    "response=agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"这是第几次调用？\"}]},\n",
    "                    config={\n",
    "                    \"configurable\": {\n",
    "                        \"thread_id\": 1,\n",
    "                        \"max_iterations\": 10,\n",
    "                    },\n",
    "                    \"recursion_limit\": 20,\n",
    "                },)\n",
    "last_message=response[\"messages\"][-1].content\n",
    "print(last_message)\n",
    "response=agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"这是第几次调用？\"}]},\n",
    "                    config={\n",
    "                    \"configurable\": {\n",
    "                        \"thread_id\": 1,\n",
    "                        \"max_iterations\": 10,\n",
    "                    },\n",
    "                    \"recursion_limit\": 20,\n",
    "                },)\n",
    "last_message=response[\"messages\"][-1].content\n",
    "print(last_message)\n",
    "response=agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"现在是几点钟？\"}]},\n",
    "                    config={\n",
    "                    \"configurable\": {\n",
    "                        \"thread_id\": 1,\n",
    "                        \"max_iterations\": 10,\n",
    "                    },\n",
    "                    \"recursion_limit\": 20,\n",
    "                },)\n",
    "last_message=response[\"messages\"][-1].content\n",
    "print(last_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1adb2",
   "metadata": {},
   "source": [
    "这样就让大模型拥有了记忆的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad093d84",
   "metadata": {},
   "source": [
    "我们发现，langchain创建的agent不能获取到当前的时间，这是我们调用的实际上是最基础的模型，最基础的模式是不具备知道时间的功能的，因此我们需要给agent添加一个获取当前时间的工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7bbf60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在是2025年11月26日 13:41:41。\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "@tool\n",
    "def get_time()->str:\n",
    "    '''用户想要知道时间的时候使用这个工具'''\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return current_time\n",
    "\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "            model=LLM_CONFIG[\"model_name\"],\n",
    "            api_key=LLM_CONFIG[\"api_key\"],\n",
    "            base_url=LLM_CONFIG[\"base_url\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "SYSTEM_PROMPT=\"你是一个智能的助理,你能够根据用户的问题来调用llm。快速的回答用户。最后回答要包含完整文案。\"\n",
    "agent = create_agent(\n",
    "            llm,\n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            tools=[get_time],\n",
    "            # checkpointer=InMemorySaver(),\n",
    "        )\n",
    "response=agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"现在是几点钟？\"}]},)\n",
    "last_message=response[\"messages\"][-1].content\n",
    "print(last_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1aca2",
   "metadata": {},
   "source": [
    "现在agent就具备一定的能力了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340ab6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11比3.9更大。\n",
      "\n",
      "虽然3.11和3.9的整数部分都是3，但比较小数部分时，0.11大于0.9，所以3.11 > 3.9。\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def clauculate(a:int,b:int)->str:\n",
    "    '''有数字比大小的时候一定要使用这个工具'''\n",
    "    if a>b:\n",
    "        return f\"{a}大于{b}\"\n",
    "    elif a<b:\n",
    "        return f\"{a}小于{b}\"\n",
    "    else:\n",
    "        return f\"{a}等于{b}\"\n",
    "\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "            model=LLM_CONFIG[\"model_name\"],\n",
    "            api_key=LLM_CONFIG[\"api_key\"],\n",
    "            base_url=LLM_CONFIG[\"base_url\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "SYSTEM_PROMPT=\"你是一个智能的助理,你能够根据用户的问题来调用llm,注意工具的调用。快速的回答用户。\"\n",
    "agent = create_agent(\n",
    "            llm,\n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            tools=[clauculate],\n",
    "            # checkpointer=InMemorySaver(),\n",
    "        )\n",
    "response=agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"3.11和3.9哪个更大？\"}]},)\n",
    "last_message=response[\"messages\"][-1].content\n",
    "print(last_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2640a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我来为您查询今天关于AI的新闻。\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(\n",
    "            model=LLM_CONFIG[\"model_name\"],\n",
    "            api_key=LLM_CONFIG[\"api_key\"],\n",
    "            base_url=LLM_CONFIG[\"base_url\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "SYSTEM_PROMPT=\"你是一个智能的助理,你能够根据用户的问题来调用llm,注意工具的调用。快速的回答用户。\"\n",
    "agent = create_agent(\n",
    "            llm,\n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            # checkpointer=InMemorySaver(),\n",
    "        )\n",
    "response=agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"今天ai有什么新闻？\"}]},)\n",
    "last_message=response[\"messages\"][-1].content\n",
    "print(last_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c5c558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据最新搜索结果，以下是关于谷歌AI模型的重要新闻：\n",
      "\n",
      "## 谷歌最新AI模型动态\n",
      "\n",
      "### Gemini 2.5系列（2024年底发布）\n",
      "- **Gemini 2.5 Pro**: 专注于深度推理能力，在数学问题、逻辑推理等方面表现突出\n",
      "- **Gemini 2.5 Flash**: 轻量级版本，注重效率和速度，响应更快，token消耗更少\n",
      "\n",
      "### Gemini 3系列（最新）\n",
      "- **Gemini 3 Pro**: 谷歌最新的旗舰模型，具有更强的多模态能力\n",
      "- **图像生成能力**: 可以生成完整可用的信息图表，准确跟随复杂提示\n",
      "- **Nano Banana Pro**: 基于Gemini 3的图像模型，能够生成高质量图像\n",
      "\n",
      "### 主要特点\n",
      "1. **多模态能力**: 支持文本、图像等多种输入输出\n",
      "2. **推理能力**: Gemini 2.5系列特别强调推理能力\n",
      "3. **图像生成**: 新版本在图像生成方面有显著提升\n",
      "4. **效率优化**: 不同版本针对不同使用场景优化\n",
      "\n",
      "谷歌正在快速推进其AI模型的发展，从Gemini 1.0到最新的Gemini 3系列，在推理能力、多模态处理和图像生成等方面都有重要突破。\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "            model=LLM_CONFIG[\"model_name\"],\n",
    "            api_key=LLM_CONFIG[\"api_key\"],\n",
    "            base_url=LLM_CONFIG[\"base_url\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "SYSTEM_PROMPT=\"你是一个智能的助理,你能够根据用户的问题来调用llm,注意工具的调用。快速的回答用户。\"\n",
    "agent = create_agent(\n",
    "            llm,\n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            tools=[DuckDuckGoSearchResults()],\n",
    "            # checkpointer=InMemorySaver(),\n",
    "        )\n",
    "response=agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"最新的ai有什么新闻?想了解最新的谷歌的模型\"}]},)\n",
    "last_message=response[\"messages\"][-1].content\n",
    "print(last_message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
