{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d742eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.tools import tool\n",
    "import asyncio\n",
    "LLM_CONFIG = {\n",
    "    # æ›¿æ¢ä¸ºä½ çš„ API Key\n",
    "    \"api_key\": \"sk-PJfHRIM2Q0K8vXajt7pBjrXFhxbVP3GSsqw6KItdSM2MvOf4\",\n",
    "    # æ›¿æ¢ä¸ºä½ çš„ API æ¥å…¥ç‚¹ (Base URL)\n",
    "    # ä¾‹å¦‚ DeepSeek: 'https://api.deepseek.com'\n",
    "    \"base_url\": \"https://api.moonshot.cn/v1\",\n",
    "    # æ›¿æ¢ä¸ºä½ éœ€è¦ä½¿ç”¨çš„æ¨¡å‹åç§°\n",
    "    \"model_name\": \"kimi-k2-turbo-preview\",\n",
    "}\n",
    "SYSTEM_PROMPT=\"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„åŠ©ç†,ä½ èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„é—®é¢˜æ¥è°ƒç”¨llmã€‚å¿«é€Ÿçš„å›ç­”ç”¨æˆ·ã€‚æœ€åå›ç­”è¦åŒ…å«å®Œæ•´æ–‡æ¡ˆï¼Œè¦æ€»ç»“ä¹‹å‰çš„æ‰€æœ‰ä¿¡æ¯,ä¸è¦åªè¯´ç”Ÿæˆå¥½äº†ã€‚\"\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "            model=LLM_CONFIG[\"model_name\"],\n",
    "            api_key=LLM_CONFIG[\"api_key\"],\n",
    "            base_url=LLM_CONFIG[\"base_url\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c547cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹æµ‹è¯•SpeechServiceç±»...\n",
      "RecognitionCallback open.\n"
     ]
    }
   ],
   "source": [
    "from dashscope.audio.asr import *\n",
    "from dashscope import MultiModalConversation\n",
    "import dashscope\n",
    "import asyncio\n",
    "import os\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import json\n",
    "import base64\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class Callback(RecognitionCallback):\n",
    "    def __init__(self, text, frames, owner) -> None:\n",
    "        self.temp_text = []\n",
    "        self.text = text\n",
    "        self.frames = frames\n",
    "        self.owner = owner\n",
    "\n",
    "    def on_open(self) -> None:\n",
    "        print(\"RecognitionCallback open.\")\n",
    "\n",
    "    def on_close(self) -> None:\n",
    "        print(\"RecognitionCallback close.\")\n",
    "        if self.temp_text:\n",
    "            self.text.extend(self.temp_text)\n",
    "            self.temp_text.clear()\n",
    "\n",
    "    def on_complete(self) -> None:\n",
    "        print(\"RecognitionCallback completed.\")  # translation completed\n",
    "        if self.temp_text:\n",
    "            self.text.extend(self.temp_text)\n",
    "            self.temp_text.clear()\n",
    "\n",
    "    def on_error(self, message) -> None:\n",
    "        print(\"RecognitionCallback task_id: \", message.request_id)\n",
    "        print(\"RecognitionCallback error: \", message.message)\n",
    "        if self.temp_text:\n",
    "            self.text.extend(self.temp_text)\n",
    "            self.temp_text.clear()\n",
    "\n",
    "    def on_event(self, result: RecognitionResult) -> None:\n",
    "        sentence = result.get_sentence()\n",
    "        if sentence is None:\n",
    "            return\n",
    "\n",
    "        if isinstance(sentence, list):\n",
    "            sentence_list = sentence\n",
    "        else:\n",
    "            sentence_list = [sentence]\n",
    "\n",
    "        for current in sentence_list:\n",
    "            if \"text\" in current:\n",
    "                print(\"RecognitionCallback text: \", current[\"text\"])\n",
    "                self.temp_text.append(current[\"text\"])\n",
    "                if RecognitionResult.is_sentence_end(current):\n",
    "                    print(\n",
    "                        \"RecognitionCallback sentence end, request_id:%s, usage:%s\"\n",
    "                        % (result.get_request_id(), result.get_usage(current))\n",
    "                    )\n",
    "                    last_text = current.get(\"text\", \"\")\n",
    "                    if last_text:\n",
    "                        self.text.append(last_text)\n",
    "                    self.temp_text.clear()\n",
    "            if \"emo_tag\" in current:\n",
    "                print(\"RecognitionCallback emo_tag: \", current[\"emo_tag\"])\n",
    "                self.owner.emo_tag = current[\"emo_tag\"]\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.temp_text.clear()\n",
    "\n",
    "\n",
    "class SpeechService:\n",
    "    def __init__(self):\n",
    "        sample_rate = 16000\n",
    "\n",
    "        # èµ„æºå­˜å‚¨å˜é‡\n",
    "        self.frames: List[np.ndarray] = []  # å£°éŸ³æ•°ç»„\n",
    "        self.transcribed_text: List[str] = []  # æ–‡æœ¬æ•°ç»„\n",
    "        self.emo_tag = None\n",
    "        \n",
    "        # åˆå§‹åŒ–dashscope\n",
    "        self.dashscope_api_key = \"sk-629432e4c14148f0a28b49d761cdc6b9\"\n",
    "        dashscope.api_key = self.dashscope_api_key\n",
    "        # çœ‹äº†å®˜æ–¹çš„api,ç›®å‰å°±æ˜¯æ”¯æŒç”¨callbackæ¥è¿›è¡Œæµå¼è°ƒç”¨,ä¹Ÿå¯ä»¥ä¸å¡«è¿™ä¸ªå‚æ•°ä¸€æ¬¡æ€§ä¼ é€’å®Œï¼Œæˆ‘é€‰æ‹©é˜»å¡çš„æ–¹æ³•å› ä¸ºæˆ‘çš„æœ€ç»ˆè½¬æ¢çš„textæ˜¯prompt,è¿™ä¸ªpromptå¿…é¡»å®Œæ•´\n",
    "        self.callback = Callback(self.transcribed_text, self.frames, self)\n",
    "        self._recognition_started = False\n",
    "        self.SpeechToTextClient = Recognition(\n",
    "            model=\"paraformer-realtime-v2\",\n",
    "            format=\"pcm\",\n",
    "            sample_rate=sample_rate,\n",
    "            heartbeat=True,\n",
    "            callback=self.callback,\n",
    "        )\n",
    "        try:\n",
    "            self.SpeechToTextClient.start()  # æµå¼çš„å¼€å§‹è¯†åˆ«\n",
    "            self._recognition_started = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing recognition: {e}\")\n",
    "            self._recognition_started = False\n",
    "        self.SpeakerClient = MultiModalConversation\n",
    "        self.is_recording = False\n",
    "\n",
    "        self.recording_thread = None\n",
    "\n",
    "        # Audio recording parameters\n",
    "        self.sample_rate = sample_rate\n",
    "        self.channels = 1\n",
    "        self.dtype = np.int16\n",
    "\n",
    "    def start_recording(self):\n",
    "        \"\"\"å¤šçº¿ç¨‹å¼€å¯å½•éŸ³\"\"\"\n",
    "        if self.is_recording:\n",
    "            return False\n",
    "\n",
    "        if not self._recognition_started:\n",
    "            try:\n",
    "                self.SpeechToTextClient.start()\n",
    "                self._recognition_started = True\n",
    "            except Exception as e:\n",
    "                print(f\"Error starting recognition: {e}\")\n",
    "                return False\n",
    "\n",
    "        if self.callback:\n",
    "            self.callback.reset()\n",
    "\n",
    "        self.is_recording = True\n",
    "        self.frames.clear()\n",
    "        self.transcribed_text.clear()\n",
    "        self.emo_tag = None\n",
    "\n",
    "        try:\n",
    "            # å½•éŸ³çš„çº¿ç¨‹\n",
    "            self.recording_thread = threading.Thread(target=self._record_audio)\n",
    "            self.recording_thread.start()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error starting recording: {e}\")\n",
    "            self.is_recording = False\n",
    "            if self._recognition_started:\n",
    "                try:\n",
    "                    self.SpeechToTextClient.stop()\n",
    "                except Exception as stop_error:\n",
    "                    print(f\"Error stopping recognition after failure: {stop_error}\")\n",
    "                self._recognition_started = False\n",
    "            return False\n",
    "\n",
    "    def stop_recording(self):\n",
    "        \"\"\"æŠŠæš‚åœçš„é€»è¾‘æ”¾åˆ°å›è°ƒå‡½æ•°äº†,è¿™ä¸ªä¿ç•™ä¸ºä¸»åŠ¨æš‚åœçš„å‡½æ•°ï¼Œå¯èƒ½ç”¨ä¸ä¸Šçš„\"\"\"\n",
    "        if not self.is_recording:\n",
    "            return None\n",
    "\n",
    "        self.is_recording = False\n",
    "\n",
    "        if self.recording_thread:\n",
    "            self.recording_thread.join()\n",
    "            self.recording_thread = None\n",
    "\n",
    "        if self._recognition_started:\n",
    "            try:\n",
    "                self.SpeechToTextClient.stop()\n",
    "            except Exception as e:\n",
    "                print(f\"Error stopping recognition: {e}\")\n",
    "            self._recognition_started = False\n",
    "        if not self.transcribed_text:\n",
    "            return None\n",
    "        return \"\".join(self.transcribed_text)\n",
    "\n",
    "    def _record_audio(self):\n",
    "        \"\"\"Record audio using sounddevice\"\"\"\n",
    "        try:\n",
    "            # Record audio until stopped\n",
    "            with sd.InputStream(\n",
    "                samplerate=self.sample_rate,\n",
    "                channels=self.channels,\n",
    "                dtype=self.dtype,\n",
    "                callback=self._audio_callback,\n",
    "            ) as stream:\n",
    "                # å½“è¿™ä¸ªç»“æŸçš„æ—¶å€™å°±æ²¡æœ‰ç»“æŸäº†\n",
    "                while self.is_recording:\n",
    "                    sd.sleep(100)  # Sleep in milliseconds\n",
    "        except Exception as e:\n",
    "            print(f\"Error recording audio: {e}\")\n",
    "\n",
    "    def _audio_callback(self, indata, frames, time_info, status):\n",
    "        \"\"\"è¿™æ˜¯æ ¸å¿ƒçš„å›è°ƒå‡½æ•°,sounddeviceæ¯å½•åˆ¶åˆ°ä¸€ä¸ªCHUNK,å°±ä¼šè°ƒç”¨ä¸€æ¬¡è¿™ä¸ªå‡½æ•°ã€‚\"\"\"\n",
    "        if not self.is_recording:\n",
    "            return\n",
    "\n",
    "        chunk = indata.copy()\n",
    "        self.frames.append(chunk)\n",
    "\n",
    "        try:\n",
    "            self.SpeechToTextClient.send_audio_frame(chunk.tobytes())\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending audio frame: {e}\")\n",
    "            self.is_recording = False\n",
    "            raise sd.CallbackStop\n",
    "\n",
    "    def record_and_transcribe(self, duration=5):\n",
    "        \"\"\"Record for specified duration and transcribe(è¿™ä¸ªåªæœ‰å¯èƒ½æ˜¯è¢«apiè°ƒç”¨äº†,æš‚æ—¶ç”¨ä¸ä¸Š)\"\"\"\n",
    "        if self.start_recording():\n",
    "            time.sleep(duration)\n",
    "            return self.stop_recording()\n",
    "        return None\n",
    "\n",
    "    def _speak_blocking(self, text: str) -> None:\n",
    "        \"\"\"é˜»å¡å¼çš„è¯­éŸ³æ’­æ”¾é€»è¾‘ï¼Œä¾›çº¿ç¨‹æ± è°ƒç”¨ã€‚\"\"\"\n",
    "        voice = self.SpeakerClient.call(\n",
    "            model=\"qwen3-tts-flash\",\n",
    "            api_key=self.dashscope_api_key,\n",
    "            text=text,\n",
    "            voice=\"Cherry\",\n",
    "            language_type=\"Chinese\",\n",
    "            stream=True,\n",
    "        )\n",
    "        try:\n",
    "            with sd.OutputStream(samplerate=24000, channels=1, dtype=\"int16\") as stream:\n",
    "                print(\"éŸ³é¢‘æµå·²å¼€å¯ï¼Œå‡†å¤‡æ’­æ”¾...\")\n",
    "                for chunk in voice:\n",
    "                    audio = chunk.output.audio\n",
    "                    if audio.data is not None:\n",
    "                        wav_bytes = base64.b64decode(audio.data)\n",
    "                        audio_np = np.frombuffer(wav_bytes, dtype=np.int16)\n",
    "                        stream.write(audio_np)\n",
    "                    if chunk.output.finish_reason == \"stop\":\n",
    "                        print(\n",
    "                            f\"æœåŠ¡ç«¯æ ‡è®°ç»“æŸï¼Œåˆ°æœŸæ—¶é—´: {chunk.output.audio.expires_at}\"\n",
    "                        )\n",
    "                print(\"éŸ³é¢‘æ•°æ®æ¥æ”¶å®Œæ¯•ï¼Œç­‰å¾…æ’­æ”¾å®Œæˆ...\")\n",
    "                time.sleep(0.8)\n",
    "        except Exception as e:\n",
    "            print(f\"æ’­æ”¾æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "\n",
    "        print(\"æ’­æ”¾ç»“æŸï¼ŒéŸ³é¢‘æµå·²è‡ªåŠ¨å…³é—­ã€‚\")\n",
    "\n",
    "    async def speak(self, text: str) -> None:\n",
    "        \"\"\"å¼‚æ­¥åœ°æ’­æ”¾è¯­éŸ³ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ã€‚\"\"\"\n",
    "        # asyncio.to_thread é€‚åˆç”¨æ¥åŒ…è£¹â€œåŸæœ¬æ˜¯åŒæ­¥/é˜»å¡â€çš„é€»è¾‘\n",
    "        await asyncio.to_thread(self._speak_blocking, text)\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up audio resources\"\"\"\n",
    "        if self.is_recording:\n",
    "            self.stop_recording()\n",
    "        if self._recognition_started:\n",
    "            try:\n",
    "                self.SpeechToTextClient.stop()\n",
    "            except Exception as e:\n",
    "                print(f\"Error stopping recognition during cleanup: {e}\")\n",
    "            self._recognition_started = False\n",
    "        self.frames.clear()\n",
    "\n",
    "    @property\n",
    "    def text(self) -> Optional[str]:\n",
    "        if not self.transcribed_text:\n",
    "            return None\n",
    "        combined_text = \"\".join(self.transcribed_text)\n",
    "        return combined_text\n",
    "\n",
    "    @property\n",
    "    def emotion(self) -> Optional[str]:\n",
    "        return self.emo_tag\n",
    "\n",
    "    def clear_text(self):\n",
    "        self.transcribed_text.clear()\n",
    "\n",
    "\n",
    "    print(\"å¼€å§‹æµ‹è¯•SpeechServiceç±»...\")\n",
    "\n",
    "# åˆ›å»ºSpeechServiceå®ä¾‹\n",
    "service = SpeechService()\n",
    "\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bf0dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Xiaohongshu Marketing Tools\n",
    "å°çº¢ä¹¦å¤¸å¼ è¥é”€æ–‡æ¡ˆå·¥å…·ï¼šä¸ºå¤§æ¨¡å‹æä¾›çˆ†æ¬¾å£å»ã€æ ‡é¢˜å’Œæ–‡æ¡ˆæ¨¡æ¿ã€‚\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def xhs_style_guide(\n",
    "    persona: str = \"ç–¯æ‰¹åå·®èŒ\",\n",
    "    emoji_density: int = 3,\n",
    "    safety_note: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    è¿”å›ä¸€ä»½å¤¸å¼ å°çº¢ä¹¦å†™ä½œæŒ‡å—ï¼Œç›´æ¥è´´ç»™å¤§æ¨¡å‹å³å¯å¥—ç”¨ã€‚\n",
    "\n",
    "    Args:\n",
    "        persona: å£å»äººè®¾ï¼Œå¦‚â€œç–¯æ‰¹åå·®èŒâ€â€œä¸“ä¸šåˆå°–å«â€\n",
    "        emoji_density: æ¯æ®µå»ºè®®æ’å…¥çš„ emoji æ•°é‡\n",
    "        safety_note: æ˜¯å¦æé†’è§„é¿åŒ»ç–—/åŠŸæ•ˆç»å¯¹åŒ–è¡¨è¿°\n",
    "\n",
    "    Returns:\n",
    "        ä¸€æ®µåŒ…å«è¯­æ°”ã€ç»“æ„ã€æ ‡ç‚¹ã€æ ‡ç­¾ç”¨æ³•çš„å†™ä½œé€ŸæŸ¥è¡¨\n",
    "    \"\"\"\n",
    "    guide = [\n",
    "        f\"äººè®¾ï¼š{persona}ï¼ŒæŠ“é©¬åˆ°ä½ä½†ä¿æŒçœŸæƒ…å®æ„Ÿï¼›å¯¹è¯»è€…ç§°å‘¼ç”¨â€œå§å¦¹ä»¬/å®å­ä»¬â€ã€‚\",\n",
    "        f\"è¯­æ°”ï¼šå¼€å¤´å¿…é¡»æƒŠå« + åå¤æ„Ÿå¹ï¼›å¤šç”¨å¤§å†™å’Œæ‹‰é•¿è¯ï¼ˆå¤ªï¼ï¼ï¼å¥½ï¼ï¼ï¼å“­äº†ï¼ï¼ï¼ï¼‰ã€‚\",\n",
    "        \"ç»“æ„ï¼šçˆ†ç‚¹å¼€å¤´ -> ä¸ªäººå´©æºƒç¬é—´/åè½¬ -> 3-5 ä¸ªç»†èŠ‚å–ç‚¹ -> å¼ºåˆ¶å®‰åˆ© + è¡ŒåŠ¨å£å·ã€‚\",\n",
    "        f\"æ ‡ç‚¹ï¼šæ„Ÿå¹å·è¿å‘ï¼Œçœç•¥å·åˆ¶é€ æ‚¬å¿µï¼›æ¯æ®µæ’å…¥çº¦ {emoji_density} ä¸ª emojiï¼ˆâš¡ï¸ğŸ¤¯ğŸ˜­âœ¨ğŸ«¶ğŸ”¥ï¼‰ã€‚\",\n",
    "        \"æ ‡ç­¾ï¼šç»“å°¾å åŠ  6-10 ä¸ªè¯é¢˜æ ‡ç­¾ï¼ŒåŒ…å«äº§å“ã€åœºæ™¯ã€æƒ…ç»ªã€è¶‹åŠ¿å…³é”®è¯ã€‚\",\n",
    "    ]\n",
    "    if safety_note:\n",
    "        guide.append(\"åˆè§„ï¼šé¿å…â€œæ²»æ„ˆ/ç™¾åˆ†ç™¾â€ä¹‹ç±»ç»å¯¹åŠŸæ•ˆè¯ï¼Œå¯ç”¨â€œç¦»è°±å¥½ç”¨â€â€œåƒå¼€æŒ‚â€ã€‚\")\n",
    "\n",
    "    return \"\\n\".join(f\"- {line}\" for line in guide)\n",
    "\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def xhs_title_pack(\n",
    "    product: str,\n",
    "    target_user: str = \"å§å¦¹ä»¬\",\n",
    "    scene: Optional[str] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆä¸€ç»„é«˜ç‚¹å‡»å°çº¢ä¹¦é£æ ¼æ ‡é¢˜ï¼Œç›´æ¥å¯ç”¨ã€‚\n",
    "\n",
    "    Args:\n",
    "        product: äº§å“/æœåŠ¡åç§°\n",
    "        target_user: ä¸»è¦å—ä¼—ç§°å‘¼\n",
    "        scene: ä½¿ç”¨åœºæ™¯æˆ–ç—›ç‚¹\n",
    "\n",
    "    Returns:\n",
    "        6-8 æ¡æ ‡é¢˜å€™é€‰ï¼Œå¸¦ emoji å’Œè¯é¢˜ä½\n",
    "    \"\"\"\n",
    "    scene_part = f\"{scene} \" if scene else \"\"\n",
    "    titles: List[str] = [\n",
    "        f\"{target_user}å´©æºƒå°–å«ï¼{scene_part}{product}çœŸçš„ç¦»è°±å¥½ç”¨ï¼ï¼ï¼âš¡ï¸ğŸ¤¯\",\n",
    "        f\"è·ªäº†ï¼{product}=å¼€æŒ‚ç¥å™¨ï¼Ÿæˆ‘è¯•å®Œæ²‰é»˜äº†ğŸ˜­\",\n",
    "        f\"ã€åˆ«å†é”™è¿‡ã€‘{scene_part}{product}è¿™æ³¢æˆ‘å¿…é¡»å…¨ç½‘å–Šï¼ï¼ï¼ğŸ”¥\",\n",
    "        f\"æ²¡æœ‰å¯¹æ¯”æ²¡æœ‰ä¼¤å®³ï¼Œ{product}æŠŠæˆ‘æ‹¿æäº†â€¦ğŸ« ğŸ«¶\",\n",
    "        f\"å¹´åº¦å¿ƒåŠ¨æ¦œç¬¬ä¸€åï¼š{product}ï¼æŠŠçŠ¶æ€æ‹‰æ»¡çš„ä¸€å¤©âœ¨\",\n",
    "        f\"å†²ï¼{product} = æˆ‘æœ€å‹‡æ•¢çš„ä¸€æ¬¡å…¥æ‰‹ï¼Œç»“æœç›´æ¥ä¸Šå¤´ğŸ˜³\",\n",
    "        f\"åè½¬äº†ï¼åŸæ¥{scene_part}{product}æ‰æ˜¯éšè—ç‹è€…ï¼Ÿï¼ğŸ¤¯\",\n",
    "    ]\n",
    "    hashtags = [\n",
    "        f\"#{product}\",\n",
    "        f\"# {scene}\" if scene else \"\",\n",
    "        \"# å¿…å…¥å¥½ç‰©\",\n",
    "        \"# å°–å«æ¨è\",\n",
    "        \"# å°ä¼—å®è—\",\n",
    "    ]\n",
    "    hashtag_line = \" \".join(tag for tag in hashtags if tag)\n",
    "    titles.append(f\"æ ‡ç­¾å¤‡é€‰ï¼š{hashtag_line}\")\n",
    "    return \"\\n\".join(f\"{idx+1}. {title}\" for idx, title in enumerate(titles))\n",
    "\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def xhs_hype_copy(\n",
    "    product: str,\n",
    "    selling_points: str,\n",
    "    audience: str = \"å§å¦¹ä»¬\",\n",
    "    scenario: str = \"æ—¥å¸¸é€šå‹¤\",\n",
    "    call_to_action: str = \"å†²ï¼é©¬ä¸Šå®‰æ’ï¼\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆä¸€ç¯‡å¤¸å¼ çš„å°çº¢ä¹¦ç§è‰æ–‡æ¡ˆï¼Œå«å¼€å¤´çˆ†ç‚¹ã€ç»†èŠ‚å–ç‚¹å’Œæ ‡ç­¾ã€‚\n",
    "\n",
    "    Args:\n",
    "        product: äº§å“/æœåŠ¡åç§°\n",
    "        selling_points: å–ç‚¹åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”\n",
    "        audience: è¯»è€…ç§°å‘¼\n",
    "        scenario: ä½¿ç”¨åœºæ™¯\n",
    "        call_to_action: è¡ŒåŠ¨å£å·\n",
    "\n",
    "    Returns:\n",
    "        ä¸€æ®µå®Œæ•´å¯ç›´æ¥å‘å¸ƒçš„å¤¸å¼ æ–‡æ¡ˆ\n",
    "    \"\"\"\n",
    "    points = [\n",
    "        p.strip() for p in selling_points.replace(\"ï¼Œ\", \",\").split(\",\") if p.strip()\n",
    "    ]\n",
    "    point_lines = \"\\n\".join(f\"Â· {idx+1}ï¼‰{p} âœ…\" for idx, p in enumerate(points))\n",
    "    if not point_lines:\n",
    "        point_lines = \"Â· å¤ªå¤šäº®ç‚¹äº†æ ¹æœ¬å†™ä¸å®Œï¼Œè‡ªå·±æ„Ÿå—ï¼ï¼\"\n",
    "\n",
    "    hashtags = [\n",
    "        f\"#{product}\",\n",
    "        f\"# {scenario}\",\n",
    "        \"# å¿…å…¥å¥½ç‰©\",\n",
    "        \"# æ‹¯æ•‘æ‰“å·¥äºº\",\n",
    "        \"# ç§è‰ä¸è¸©é›·\",\n",
    "        \"# çˆ†æ”¹ç”Ÿæ´»\",\n",
    "    ]\n",
    "    header = (\n",
    "        f\"{audience}ï¼ï¼ï¼æˆ‘ç›´æ¥ç ´é˜²ï¼{scenario}è¢«{product}ç‹ ç‹ æ‹¿æï¼Œå¤ªç‚¸è£‚äº†ğŸ˜­ğŸ˜­ğŸ˜­\"\n",
    "    )\n",
    "    story = (\n",
    "        f\"æœ¬æ¥åªæƒ³éšä¾¿è¯•è¯•ï¼Œç»“æœä¸€ä¸Šæ‰‹å°±åƒå¼€æŒ‚ï¼Œç¦»è°±åˆ°æƒ³å†²è¿›è¯„è®ºåŒºå–Šåœï¼\"\n",
    "        f\" ç»†èŠ‚æˆ‘æ°å¼€æ‰ç¢å‘Šè¯‰ä½ ï¼š\"\n",
    "    )\n",
    "    cta = f\"{call_to_action} ä¸å†²çœŸçš„ä¼šåæ‚”ä¸€æ•´å¹´ï¼\"\n",
    "\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            header,\n",
    "            \"â€”\" * 10,\n",
    "            story,\n",
    "            point_lines,\n",
    "            \"â€”\" * 10,\n",
    "            cta,\n",
    "            \" \".join(hashtags),\n",
    "        ]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6dc28f",
   "metadata": {},
   "source": [
    "ä¸‡äº‹å…·å¤‡ï¼Œæˆ‘ä»¬ç°åœ¨æ¥åˆ›å»ºæˆ‘ä»¬çš„agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å§å¦¹ä»¬ï¼ï¼ï¼æˆ‘ç›´æ¥ç ´é˜²ï¼æ ¡å›­æ—¥å¸¸ä¸Šè¯¾,å›¾ä¹¦é¦†å­¦ä¹ ,å‘¨æœ«é€›è¡—,çº¦ä¼šèšé¤è¢«ç™¾æ­å­¦ç”Ÿå…šè¡£æœç‹ ç‹ æ‹¿æï¼Œå¤ªç‚¸è£‚äº†ğŸ˜­ğŸ˜­ğŸ˜­\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "æœ¬æ¥åªæƒ³éšä¾¿è¯•è¯•ï¼Œç»“æœä¸€ä¸Šæ‰‹å°±åƒå¼€æŒ‚ï¼Œç¦»è°±åˆ°æƒ³å†²è¿›è¯„è®ºåŒºå–Šåœï¼ ç»†èŠ‚æˆ‘æ°å¼€æ‰ç¢å‘Šè¯‰ä½ ï¼š\n",
      "Â· 1ï¼‰å¹³ä»·ç™¾æ­ âœ…\n",
      "Â· 2ï¼‰èˆ’é€‚é€æ°” âœ…\n",
      "Â· 3ï¼‰æ ¡å›­æ—¥å¸¸é€šå‹¤ âœ…\n",
      "Â· 4ï¼‰ä¸æŒ‘èº«æ âœ…\n",
      "Â· 5ï¼‰å¤šè‰²å¯é€‰ âœ…\n",
      "Â· 6ï¼‰æ˜“æ­é… âœ…\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "å­¦ç”Ÿå…šå†²é¸­ï¼é©¬ä¸Šå®‰æ’ï¼ ä¸å†²çœŸçš„ä¼šåæ‚”ä¸€æ•´å¹´ï¼\n",
      "#ç™¾æ­å­¦ç”Ÿå…šè¡£æœ # æ ¡å›­æ—¥å¸¸ä¸Šè¯¾,å›¾ä¹¦é¦†å­¦ä¹ ,å‘¨æœ«é€›è¡—,çº¦ä¼šèšé¤ # å¿…å…¥å¥½ç‰© # æ‹¯æ•‘æ‰“å·¥äºº # ç§è‰ä¸è¸©é›· # çˆ†æ”¹ç”Ÿæ´»\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT=\"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„åŠ©ç†,ä½ èƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ¥ç”Ÿæˆå°çº¢ä¹¦çš„æ–‡æ¡ˆï¼Œä¸€å®šè¦ç”¨å·¥å…·çš„è°ƒç”¨æ¥ç”Ÿæˆè¿™æ ·çš„é£æ ¼çš„æ–‡æ¡ˆã€‚\"\n",
    "\n",
    "agent = create_agent(\n",
    "            llm,\n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            tools=[xhs_style_guide,xhs_title_pack,xhs_hype_copy],\n",
    "            checkpointer=InMemorySaver(),\n",
    "        )\n",
    "\n",
    "response=agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"å¸®æˆ‘ç”Ÿæˆä¸€ä¸ªå–è¡£æœçš„å°çº¢ä¹¦æ–‡æ¡ˆ,ä¸€ä¸ªç™¾æ­è€Œä¸”é€‚åˆå­¦ç”Ÿå…šçš„è¡£æœã€‚\"}]},\n",
    "                    config={\n",
    "                    \"configurable\": {\n",
    "                        \"thread_id\": 1,\n",
    "                        \"max_iterations\": 10,\n",
    "                    },\n",
    "                    \"recursion_limit\": 20,\n",
    "                },)\n",
    "last_message=response[\"messages\"][-1].content\n",
    "print(last_message)\n",
    "\n",
    "await service.speak(last_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
